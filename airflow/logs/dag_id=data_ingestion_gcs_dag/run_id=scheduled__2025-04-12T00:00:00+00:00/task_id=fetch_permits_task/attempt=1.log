[2025-04-13T02:45:20.741+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T02:45:20.752+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T02:45:20.756+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T02:45:20.756+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T02:45:20.763+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T02:45:20.767+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T02:45:20.768+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T02:45:20.769+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpb_9n8i85']
[2025-04-13T02:45:20.769+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T02:45:20.798+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 84c96c34f493
[2025-04-13T02:45:20.836+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T02:45:20.837+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T02:45:20.837+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T02:45:20.837+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 02:45:20.752545+00:00
[2025-04-13T02:45:20.838+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T02:45:20.838+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T02:45:20.838+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 51, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
IsADirectoryError: [Errno 21] Is a directory: '/opt/nyc_od_app_token.txt'
[2025-04-13T02:45:20.845+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T02:45:20.845+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 02:45:20.752545+00:00 end:2025-04-13 02:45:20.845285+00:00 duration:0.09274
[2025-04-13T02:45:20.845+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 02:45:15.803784+00:00. externally triggered: False>
[2025-04-13T02:45:20.846+0000] {logging_mixin.py:190} INFO - Failure caused by [Errno 21] Is a directory: '/opt/nyc_od_app_token.txt'
[2025-04-13T02:45:20.846+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T024520, end_date=20250413T024520
[2025-04-13T02:45:20.861+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T02:45:20.862+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task ([Errno 21] Is a directory: '/opt/nyc_od_app_token.txt'; 85)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 51, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
IsADirectoryError: [Errno 21] Is a directory: '/opt/nyc_od_app_token.txt'
[2025-04-13T02:45:20.868+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T02:45:20.880+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T02:45:20.881+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T03:03:10.119+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T03:03:10.129+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:03:10.134+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:03:10.134+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T03:03:10.141+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T03:03:10.145+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T03:03:10.146+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T03:03:10.146+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpf4easub0']
[2025-04-13T03:03:10.147+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T03:03:10.173+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 198303a87d4f
[2025-04-13T03:03:10.211+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T03:03:10.212+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T03:03:10.212+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T03:03:10.212+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 03:03:10.129933+00:00
[2025-04-13T03:03:10.212+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T03:03:10.213+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T03:03:10.213+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 51, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/nyc_od_app_token.txt'
[2025-04-13T03:03:10.221+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T03:03:10.221+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 03:03:10.129933+00:00 end:2025-04-13 03:03:10.220916+00:00 duration:0.090983
[2025-04-13T03:03:10.221+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 03:03:05.231424+00:00. externally triggered: False>
[2025-04-13T03:03:10.221+0000] {logging_mixin.py:190} INFO - Failure caused by [Errno 2] No such file or directory: '/nyc_od_app_token.txt'
[2025-04-13T03:03:10.221+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T030310, end_date=20250413T030310
[2025-04-13T03:03:10.234+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T03:03:10.235+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task ([Errno 2] No such file or directory: '/nyc_od_app_token.txt'; 85)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 51, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: '/nyc_od_app_token.txt'
[2025-04-13T03:03:10.244+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T03:03:10.251+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T03:09:14.565+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T03:09:14.578+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:09:14.583+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:09:14.584+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T03:09:14.591+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T03:09:14.596+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T03:09:14.597+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T03:09:14.599+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpitriahr7']
[2025-04-13T03:09:14.599+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T03:09:14.633+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host c02a160e6d99
[2025-04-13T03:09:14.673+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T03:09:14.675+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T03:09:14.675+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T03:09:14.675+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 03:09:14.578926+00:00
[2025-04-13T03:09:14.675+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T03:09:14.675+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T03:09:20.540+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T03:09:20.546+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T03:09:20.546+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T030914, end_date=20250413T030920
[2025-04-13T03:09:20.560+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T03:09:20.560+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T03:09:20.560+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 03:09:10.289015+00:00
[2025-04-13T03:09:20.560+0000] {logging_mixin.py:190} INFO - Task hostname:c02a160e6d99 operator:PythonOperator
[2025-04-13T03:09:20.605+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T03:09:20.654+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T03:09:20.658+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T03:19:39.997+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T03:19:40.007+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:19:40.012+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T03:19:40.012+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T03:19:40.019+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T03:19:40.022+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=90) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T03:19:40.023+0000] {standard_task_runner.py:72} INFO - Started process 92 to run task
[2025-04-13T03:19:40.024+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_mnjrxg9']
[2025-04-13T03:19:40.024+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T03:19:40.054+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 1b4e74840e23
[2025-04-13T03:19:40.102+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T03:19:40.103+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T03:19:40.103+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T03:19:40.104+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 03:19:40.008169+00:00
[2025-04-13T03:19:40.104+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T03:19:40.104+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T03:19:46.074+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T03:19:46.080+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T03:19:46.080+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T031940, end_date=20250413T031946
[2025-04-13T03:19:46.095+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T03:19:46.096+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T03:19:46.096+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 03:19:35.051757+00:00
[2025-04-13T03:19:46.096+0000] {logging_mixin.py:190} INFO - Task hostname:1b4e74840e23 operator:PythonOperator
[2025-04-13T03:19:46.119+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T03:19:46.134+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T03:19:46.135+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:26:01.569+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:26:01.580+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:26:01.584+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:26:01.585+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:26:01.591+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:26:01.595+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:26:01.596+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T04:26:01.597+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp60q7q20v']
[2025-04-13T04:26:01.598+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T04:26:01.622+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host e117c5077d30
[2025-04-13T04:26:01.661+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:26:01.662+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:26:01.662+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:26:01.663+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 04:26:01.580648+00:00
[2025-04-13T04:26:01.663+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:26:01.663+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:26:02.184+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in fetch_permits
    results = client.get(DATASET_ID, offset=offset, limit=batch_size, where=f"issued_date > '{ti}'")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:26:02.192+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T04:26:02.193+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 04:26:01.580648+00:00 end:2025-04-13 04:26:02.192458+00:00 duration:0.61181
[2025-04-13T04:26:02.193+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 04:25:56.583174+00:00. externally triggered: False>
[2025-04-13T04:26:02.193+0000] {logging_mixin.py:190} INFO - Failure caused by 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:26:02.193+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T042601, end_date=20250413T042602
[2025-04-13T04:26:02.212+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:26:02.213+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task (400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^"); 85)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in fetch_permits
    results = client.get(DATASET_ID, offset=offset, limit=batch_size, where=f"issued_date > '{ti}'")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:26:02.227+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T04:26:02.248+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:26:02.249+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:40:18.564+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:40:18.576+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:40:18.581+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:40:18.581+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:40:18.587+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:40:18.591+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=84) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:40:18.592+0000] {standard_task_runner.py:72} INFO - Started process 86 to run task
[2025-04-13T04:40:18.593+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp9xnyhc9k']
[2025-04-13T04:40:18.593+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T04:40:18.618+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 2cb45634cec3
[2025-04-13T04:40:18.659+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:40:18.660+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:40:18.660+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:40:18.660+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 04:40:18.577250+00:00
[2025-04-13T04:40:18.660+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:40:18.660+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:40:19.332+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in fetch_permits
    results = client.get(DATASET_ID, offset=offset, limit=batch_size, where=f"issued_date > '{ti}'")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:40:19.353+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T04:40:19.353+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 04:40:18.577250+00:00 end:2025-04-13 04:40:19.352766+00:00 duration:0.775516
[2025-04-13T04:40:19.354+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 04:40:13.583186+00:00. externally triggered: False>
[2025-04-13T04:40:19.354+0000] {logging_mixin.py:190} INFO - Failure caused by 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:40:19.354+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T044018, end_date=20250413T044019
[2025-04-13T04:40:19.390+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:40:19.390+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task (400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^"); 86)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 61, in fetch_permits
    results = client.get(DATASET_ID, offset=offset, limit=batch_size, where=f"issued_date > '{ti}'")
              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.type-mismatch; Type mismatch for op$>, is text; position: Map(row -> 1, column -> 727, line -> "SELECT `job_filing_number`, `filing_reason`, `house_no`, `street_name`, `borough`, `lot`, `bin`, `block`, `c_b_no`, `apt_condo_no_s`, `work_on_floor`, `work_type`, `permittee_s_license_type`, `applicant_license`, `applicant_first_name`, `applicant_middle_name`, `applicant_last_name`, `applicant_business_name`, `applicant_business_address`, `filing_representative_first_name`, `filing_representative_middle_initial`, `filing_representative_last_name`, `filing_representative_business_name`, `work_permit`, `approved_date`, `issued_date`, `expired_date`, `job_description`, `estimated_job_costs`, `owner_business_name`, `owner_name`, `owner_street_address`, `owner_city`, `owner_state`, `owner_zip_code` WHERE `issued_date` > \"None\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      ^")
[2025-04-13T04:40:19.430+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T04:40:19.467+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:40:19.469+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:51:44.674+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:51:44.684+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:51:44.689+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:51:44.689+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:51:44.695+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:51:44.699+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=90) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:51:44.700+0000] {standard_task_runner.py:72} INFO - Started process 92 to run task
[2025-04-13T04:51:44.701+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpy87_1_6k']
[2025-04-13T04:51:44.701+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T04:51:44.725+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host dbcd52eb1b2e
[2025-04-13T04:51:44.762+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:51:44.763+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:51:44.764+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:51:44.764+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 04:51:44.684968+00:00
[2025-04-13T04:51:44.764+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:51:44.764+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:51:44.764+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 53, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/nyc_od_app_token.txt'
[2025-04-13T04:51:44.773+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T04:51:44.773+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 04:51:44.684968+00:00 end:2025-04-13 04:51:44.773201+00:00 duration:0.088233
[2025-04-13T04:51:44.773+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 04:51:39.748271+00:00. externally triggered: False>
[2025-04-13T04:51:44.774+0000] {logging_mixin.py:190} INFO - Failure caused by [Errno 2] No such file or directory: 'opt/***/nyc_od_app_token.txt'
[2025-04-13T04:51:44.774+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T045144, end_date=20250413T045144
[2025-04-13T04:51:44.788+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:51:44.788+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task ([Errno 2] No such file or directory: 'opt/airflow/nyc_od_app_token.txt'; 92)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 53, in fetch_permits
    with open(token_file_path, 'r') as file:
         ^^^^^^^^^^^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'opt/airflow/nyc_od_app_token.txt'
[2025-04-13T04:51:44.801+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T04:51:44.806+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:54:57.615+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:54:57.625+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:54:57.629+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:54:57.630+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:54:57.636+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:54:57.640+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:54:57.641+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T04:54:57.642+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsfhc_oso']
[2025-04-13T04:54:57.642+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T04:54:57.668+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 2bc808719a13
[2025-04-13T04:54:57.705+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:54:57.706+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:54:57.706+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:54:57.706+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 04:54:57.625772+00:00
[2025-04-13T04:54:57.707+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:54:57.707+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:55:02.785+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T04:55:02.793+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:55:02.793+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T045457, end_date=20250413T045502
[2025-04-13T04:55:02.805+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T04:55:02.806+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T04:55:02.806+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 04:54:53.369753+00:00
[2025-04-13T04:55:02.806+0000] {logging_mixin.py:190} INFO - Task hostname:2bc808719a13 operator:PythonOperator
[2025-04-13T04:55:02.837+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T04:55:02.867+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:55:02.868+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T05:00:25.191+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T05:00:25.206+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:00:25.210+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:00:25.211+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T05:00:25.217+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T05:00:25.221+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=84) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T05:00:25.222+0000] {standard_task_runner.py:72} INFO - Started process 86 to run task
[2025-04-13T05:00:25.224+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpje25m91k']
[2025-04-13T05:00:25.224+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T05:00:25.249+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 6cba399dd19a
[2025-04-13T05:00:25.292+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T05:00:25.293+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T05:00:25.294+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T05:00:25.294+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 05:00:25.207126+00:00
[2025-04-13T05:00:25.294+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T05:00:25.294+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T05:00:29.396+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T05:00:29.402+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T05:00:29.402+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T050025, end_date=20250413T050029
[2025-04-13T05:00:29.415+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T05:00:29.416+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T05:00:29.416+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 05:00:20.262467+00:00
[2025-04-13T05:00:29.416+0000] {logging_mixin.py:190} INFO - Task hostname:6cba399dd19a operator:PythonOperator
[2025-04-13T05:00:29.429+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T05:00:29.449+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T05:00:29.449+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T05:07:07.841+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T05:07:07.852+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:07:07.856+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:07:07.857+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T05:07:07.863+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T05:07:07.867+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T05:07:07.868+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T05:07:07.868+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpj7b3px36']
[2025-04-13T05:07:07.869+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T05:07:07.896+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host d7194c8f2778
[2025-04-13T05:07:07.933+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T05:07:07.934+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T05:07:07.934+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T05:07:07.934+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 05:07:07.852689+00:00
[2025-04-13T05:07:07.934+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T05:07:07.934+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T05:14:25.228+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T05:14:25.240+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T05:14:25.241+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T050707, end_date=20250413T051425
[2025-04-13T05:14:25.257+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T05:14:25.257+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T05:14:25.258+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 05:07:02.854448+00:00
[2025-04-13T05:14:25.258+0000] {logging_mixin.py:190} INFO - Task hostname:d7194c8f2778 operator:PythonOperator
[2025-04-13T05:14:25.349+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T05:14:25.381+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T05:14:25.381+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:34:58.273+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:34:58.284+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:34:58.289+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:34:58.290+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:34:58.296+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:34:58.300+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:34:58.301+0000] {standard_task_runner.py:72} INFO - Started process 92 to run task
[2025-04-13T16:34:58.301+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm8mtoqon']
[2025-04-13T16:34:58.302+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T16:34:58.328+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host c8daa6a1af90
[2025-04-13T16:34:58.365+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:34:58.366+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:34:58.367+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:34:58.367+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 16:34:58.284881+00:00
[2025-04-13T16:34:58.367+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:34:58.367+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:34:59.683+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T16:34:59.688+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:34:59.689+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T163458, end_date=20250413T163459
[2025-04-13T16:34:59.700+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:34:59.701+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:34:59.701+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:34:52.260133+00:00
[2025-04-13T16:34:59.701+0000] {logging_mixin.py:190} INFO - Task hostname:c8daa6a1af90 operator:PythonOperator
[2025-04-13T16:34:59.712+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:34:59.725+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:34:59.726+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:45:34.902+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:45:34.915+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:45:34.920+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:45:34.920+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:45:34.926+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:45:34.930+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=146) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:45:34.931+0000] {standard_task_runner.py:72} INFO - Started process 148 to run task
[2025-04-13T16:45:34.933+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpv7bor4rf']
[2025-04-13T16:45:34.934+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T16:45:34.960+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host c4adc78e7cfa
[2025-04-13T16:45:34.997+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:45:34.998+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:45:34.998+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:45:34.998+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 16:45:34.915565+00:00
[2025-04-13T16:45:34.998+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:45:34.999+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:45:36.113+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T16:45:36.118+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:45:36.119+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T164534, end_date=20250413T164536
[2025-04-13T16:45:36.129+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:45:36.130+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:45:36.130+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:45:29.898336+00:00
[2025-04-13T16:45:36.130+0000] {logging_mixin.py:190} INFO - Task hostname:c4adc78e7cfa operator:PythonOperator
[2025-04-13T16:45:36.138+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:45:36.151+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:45:36.153+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:49:51.438+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:49:51.452+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:49:51.457+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:49:51.458+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:49:51.467+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:49:51.471+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:49:51.472+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T16:49:51.474+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpd8s6sce2']
[2025-04-13T16:49:51.475+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T16:49:51.506+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host f05686b2dc59
[2025-04-13T16:49:51.555+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:49:51.556+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:49:51.556+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:49:51.556+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 16:49:51.453059+00:00
[2025-04-13T16:49:51.557+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:49:51.557+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:49:52.914+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T16:49:52.920+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:49:52.921+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T164951, end_date=20250413T164952
[2025-04-13T16:49:52.936+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:49:52.937+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:49:52.938+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:49:46.134601+00:00
[2025-04-13T16:49:52.938+0000] {logging_mixin.py:190} INFO - Task hostname:f05686b2dc59 operator:PythonOperator
[2025-04-13T16:49:52.966+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:49:52.983+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:49:52.988+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T17:06:46.879+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T17:06:46.891+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T17:06:46.895+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T17:06:46.895+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T17:06:46.901+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T17:06:46.905+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=104) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T17:06:46.906+0000] {standard_task_runner.py:72} INFO - Started process 106 to run task
[2025-04-13T17:06:46.907+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppel4otrf']
[2025-04-13T17:06:46.907+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T17:06:46.933+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 1cc4ef4172c3
[2025-04-13T17:06:46.974+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T17:06:46.975+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T17:06:46.976+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T17:06:46.976+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 17:06:46.891286+00:00
[2025-04-13T17:06:46.976+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T17:06:46.976+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T17:06:48.169+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T17:06:48.174+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T17:06:48.175+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T170646, end_date=20250413T170648
[2025-04-13T17:06:48.186+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T17:06:48.186+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T17:06:48.186+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 17:06:41.545310+00:00
[2025-04-13T17:06:48.186+0000] {logging_mixin.py:190} INFO - Task hostname:1cc4ef4172c3 operator:PythonOperator
[2025-04-13T17:06:48.194+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T17:06:48.208+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T17:06:48.209+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T22:50:01.753+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T22:50:01.765+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:50:01.770+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:50:01.770+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T22:50:01.776+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T22:50:01.780+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=222) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T22:50:01.781+0000] {standard_task_runner.py:72} INFO - Started process 224 to run task
[2025-04-13T22:50:01.782+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpvxhsy2x2']
[2025-04-13T22:50:01.782+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T22:50:01.811+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host e66f5071272b
[2025-04-13T22:50:01.850+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T22:50:01.851+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T22:50:01.852+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T22:50:01.852+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 22:50:01.765302+00:00
[2025-04-13T22:50:01.852+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T22:50:01.852+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T22:50:01.859+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-10 (offset=0)
[2025-04-13T22:50:02.440+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 85, in fetch_permits
    results = client.get(
              ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.no-such-column; No such column: issued_date; position: Map(row -> 1, column -> 1141, line -> "SELECT `borough`, `bin__`, `house__`, `street_name`, `job__`, `job_doc___`, `job_type`, `self_cert`, `block`, `lot`, `community_board`, `zip_code`, `bldg_type`, `residential`, `special_district_1`, `special_district_2`, `work_type`, `permit_status`, `filing_status`, `permit_type`, `permit_sequence__`, `permit_subtype`, `oil_gas`, `site_fill`, `filing_date`, `issuance_date`, `expiration_date`, `job_start_date`, `permittee_s_first_name`, `permittee_s_last_name`, `permittee_s_business_name`, `permittee_s_phone__`, `permittee_s_license_type`, `permittee_s_license__`, `act_as_superintendent`, `permittee_s_other_title`, `hic_license`, `site_safety_mgr_s_first_name`, `site_safety_mgr_s_last_name`, `site_safety_mgr_business_name`, `superintendent_first___last_name`, `superintendent_business_name`, `owner_s_business_type`, `non_profit`, `owner_s_business_name`, `owner_s_first_name`, `owner_s_last_name`, `owner_s_house__`, `owner_s_house_street_name`, `city`, `state`, `owner_s_zip_code`, `owner_s_phone__`, `dobrundate`, `permit_si_no`, `gis_latitude`, `gis_longitude`, `gis_council_district`, `gis_census_tract`, `gis_nta_name` WHERE `issued_date` = \"04/10/2025\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^")
[2025-04-13T22:50:02.466+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T22:50:02.467+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 22:50:01.765302+00:00 end:2025-04-13 22:50:02.466572+00:00 duration:0.70127
[2025-04-13T22:50:02.467+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): fetch_permits_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 22:49:56.330855+00:00. externally triggered: False>
[2025-04-13T22:50:02.467+0000] {logging_mixin.py:190} INFO - Failure caused by 400 Client Error: Bad Request.
	Query coordinator error: query.soql.no-such-column; No such column: issued_date; position: Map(row -> 1, column -> 1141, line -> "SELECT `borough`, `bin__`, `house__`, `street_name`, `job__`, `job_doc___`, `job_type`, `self_cert`, `block`, `lot`, `community_board`, `zip_code`, `bldg_type`, `residential`, `special_district_1`, `special_district_2`, `work_type`, `permit_status`, `filing_status`, `permit_type`, `permit_sequence__`, `permit_subtype`, `oil_gas`, `site_fill`, `filing_date`, `issuance_date`, `expiration_date`, `job_start_date`, `permittee_s_first_name`, `permittee_s_last_name`, `permittee_s_business_name`, `permittee_s_phone__`, `permittee_s_license_type`, `permittee_s_license__`, `act_as_superintendent`, `permittee_s_other_title`, `hic_license`, `site_safety_mgr_s_first_name`, `site_safety_mgr_s_last_name`, `site_safety_mgr_business_name`, `superintendent_first___last_name`, `superintendent_business_name`, `owner_s_business_type`, `non_profit`, `owner_s_business_name`, `owner_s_first_name`, `owner_s_last_name`, `owner_s_house__`, `owner_s_house_street_name`, `city`, `state`, `owner_s_zip_code`, `owner_s_phone__`, `dobrundate`, `permit_si_no`, `gis_latitude`, `gis_longitude`, `gis_council_district`, `gis_census_tract`, `gis_nta_name` WHERE `issued_date` = \"04/10/2025\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^")
[2025-04-13T22:50:02.467+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T225001, end_date=20250413T225002
[2025-04-13T22:50:02.485+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T22:50:02.485+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 4 for task fetch_permits_task (400 Client Error: Bad Request.
	Query coordinator error: query.soql.no-such-column; No such column: issued_date; position: Map(row -> 1, column -> 1141, line -> "SELECT `borough`, `bin__`, `house__`, `street_name`, `job__`, `job_doc___`, `job_type`, `self_cert`, `block`, `lot`, `community_board`, `zip_code`, `bldg_type`, `residential`, `special_district_1`, `special_district_2`, `work_type`, `permit_status`, `filing_status`, `permit_type`, `permit_sequence__`, `permit_subtype`, `oil_gas`, `site_fill`, `filing_date`, `issuance_date`, `expiration_date`, `job_start_date`, `permittee_s_first_name`, `permittee_s_last_name`, `permittee_s_business_name`, `permittee_s_phone__`, `permittee_s_license_type`, `permittee_s_license__`, `act_as_superintendent`, `permittee_s_other_title`, `hic_license`, `site_safety_mgr_s_first_name`, `site_safety_mgr_s_last_name`, `site_safety_mgr_business_name`, `superintendent_first___last_name`, `superintendent_business_name`, `owner_s_business_type`, `non_profit`, `owner_s_business_name`, `owner_s_first_name`, `owner_s_last_name`, `owner_s_house__`, `owner_s_house_street_name`, `city`, `state`, `owner_s_zip_code`, `owner_s_phone__`, `dobrundate`, `permit_si_no`, `gis_latitude`, `gis_longitude`, `gis_council_district`, `gis_census_tract`, `gis_nta_name` WHERE `issued_date` = \"04/10/2025\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^"); 224)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 85, in fetch_permits
    results = client.get(
              ^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 412, in get
    response = self._perform_request(
               ^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/socrata.py", line 555, in _perform_request
    utils.raise_for_status(response)
  File "/home/airflow/.local/lib/python3.12/site-packages/sodapy/utils.py", line 30, in raise_for_status
    raise requests.exceptions.HTTPError(http_error_msg, response=response)
requests.exceptions.HTTPError: 400 Client Error: Bad Request.
	Query coordinator error: query.soql.no-such-column; No such column: issued_date; position: Map(row -> 1, column -> 1141, line -> "SELECT `borough`, `bin__`, `house__`, `street_name`, `job__`, `job_doc___`, `job_type`, `self_cert`, `block`, `lot`, `community_board`, `zip_code`, `bldg_type`, `residential`, `special_district_1`, `special_district_2`, `work_type`, `permit_status`, `filing_status`, `permit_type`, `permit_sequence__`, `permit_subtype`, `oil_gas`, `site_fill`, `filing_date`, `issuance_date`, `expiration_date`, `job_start_date`, `permittee_s_first_name`, `permittee_s_last_name`, `permittee_s_business_name`, `permittee_s_phone__`, `permittee_s_license_type`, `permittee_s_license__`, `act_as_superintendent`, `permittee_s_other_title`, `hic_license`, `site_safety_mgr_s_first_name`, `site_safety_mgr_s_last_name`, `site_safety_mgr_business_name`, `superintendent_first___last_name`, `superintendent_business_name`, `owner_s_business_type`, `non_profit`, `owner_s_business_name`, `owner_s_first_name`, `owner_s_last_name`, `owner_s_house__`, `owner_s_house_street_name`, `city`, `state`, `owner_s_zip_code`, `owner_s_phone__`, `dobrundate`, `permit_si_no`, `gis_latitude`, `gis_longitude`, `gis_council_district`, `gis_census_tract`, `gis_nta_name` WHERE `issued_date` = \"04/10/2025\" LIMIT 1000 OFFSET 0\n                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                    ^")
[2025-04-13T22:50:02.495+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T22:50:02.508+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T22:50:02.509+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T22:52:01.740+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T22:52:01.750+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:52:01.756+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:52:01.756+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T22:52:01.762+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T22:52:01.766+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=90) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T22:52:01.766+0000] {standard_task_runner.py:72} INFO - Started process 92 to run task
[2025-04-13T22:52:01.768+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsvapnc_d']
[2025-04-13T22:52:01.770+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T22:52:01.795+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host f545404fc07f
[2025-04-13T22:52:01.833+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T22:52:01.835+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T22:52:01.835+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T22:52:01.836+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 22:52:01.751266+00:00
[2025-04-13T22:52:01.836+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T22:52:01.836+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T22:52:01.844+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-10 (offset=0)
[2025-04-13T22:52:03.046+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-11 (offset=0)
[2025-04-13T22:52:03.418+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-12 (offset=0)
[2025-04-13T22:52:03.579+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-13 (offset=0)
[2025-04-13T22:52:03.808+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T22:52:03.813+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T22:52:03.814+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T225201, end_date=20250413T225203
[2025-04-13T22:52:03.826+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T22:52:03.826+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T22:52:03.826+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 22:51:56.480715+00:00
[2025-04-13T22:52:03.826+0000] {logging_mixin.py:190} INFO - Task hostname:f545404fc07f operator:PythonOperator
[2025-04-13T22:52:03.873+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T22:52:03.910+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T22:52:03.912+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:07:42.711+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:07:42.723+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:07:42.729+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:07:42.731+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:07:42.739+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:07:42.746+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmperxczft4']
[2025-04-13T23:07:42.746+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:07:42.747+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:07:42.747+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T23:07:42.775+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 3aaac60a2eb2
[2025-04-13T23:07:42.820+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:07:42.822+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:07:42.823+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:07:42.823+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:07:42.725035+00:00
[2025-04-13T23:07:42.823+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:07:42.823+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:07:42.832+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-10 (offset=0)
[2025-04-13T23:07:43.590+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-11 (offset=0)
[2025-04-13T23:07:44.342+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-12 (offset=0)
[2025-04-13T23:07:44.529+0000] {logging_mixin.py:190} INFO - Fetching records for 2025-04-13 (offset=0)
[2025-04-13T23:07:44.732+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:07:44.738+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:07:44.738+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T230742, end_date=20250413T230744
[2025-04-13T23:07:44.755+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:07:44.756+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:07:44.759+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:07:36.629415+00:00
[2025-04-13T23:07:44.760+0000] {logging_mixin.py:190} INFO - Task hostname:3aaac60a2eb2 operator:PythonOperator
[2025-04-13T23:07:44.776+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:07:44.792+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:07:44.793+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:30:48.130+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:30:48.141+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:30:48.145+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:30:48.146+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:30:48.152+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:30:48.156+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=105) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:30:48.157+0000] {standard_task_runner.py:72} INFO - Started process 107 to run task
[2025-04-13T23:30:48.159+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjtayuafp']
[2025-04-13T23:30:48.160+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:30:48.186+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 15a7108b06f8
[2025-04-13T23:30:48.225+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:30:48.226+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:30:48.226+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:30:48.227+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:30:48.141732+00:00
[2025-04-13T23:30:48.227+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:30:48.227+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:30:48.232+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-14 (offset=0)
[2025-04-13T23:30:49.251+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-15 (offset=0)
[2025-04-13T23:30:49.633+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-16 (offset=0)
[2025-04-13T23:30:50.008+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-17 (offset=0)
[2025-04-13T23:30:50.362+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-18 (offset=0)
[2025-04-13T23:30:50.665+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-19 (offset=0)
[2025-04-13T23:30:50.991+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-20 (offset=0)
[2025-04-13T23:30:51.367+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-21 (offset=0)
[2025-04-13T23:30:51.719+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-22 (offset=0)
[2025-04-13T23:30:52.043+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-23 (offset=0)
[2025-04-13T23:30:52.455+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:30:52.461+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:30:52.461+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T233048, end_date=20250413T233052
[2025-04-13T23:30:52.477+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:30:52.477+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:30:52.477+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:30:43.197349+00:00
[2025-04-13T23:30:52.477+0000] {logging_mixin.py:190} INFO - Task hostname:15a7108b06f8 operator:PythonOperator
[2025-04-13T23:30:52.518+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:30:52.559+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:30:52.560+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:37:36.677+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:37:36.688+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:37:36.693+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:37:36.693+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:37:36.700+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:37:36.704+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:37:36.705+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T23:37:36.707+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppmgz4z7s']
[2025-04-13T23:37:36.710+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:37:36.738+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 84d443f8c8f3
[2025-04-13T23:37:36.784+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:37:36.786+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:37:36.786+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:37:36.786+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:37:36.688703+00:00
[2025-04-13T23:37:36.786+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:37:36.787+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:37:36.795+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-14 (offset=0)
[2025-04-13T23:37:37.737+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-15 (offset=0)
[2025-04-13T23:37:38.086+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-16 (offset=0)
[2025-04-13T23:37:38.410+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-17 (offset=0)
[2025-04-13T23:37:38.773+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-18 (offset=0)
[2025-04-13T23:37:39.098+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-19 (offset=0)
[2025-04-13T23:37:39.403+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-20 (offset=0)
[2025-04-13T23:37:39.726+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-21 (offset=0)
[2025-04-13T23:37:40.069+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-22 (offset=0)
[2025-04-13T23:37:40.416+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-23 (offset=0)
[2025-04-13T23:37:40.821+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:37:40.829+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:37:40.829+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T233736, end_date=20250413T233740
[2025-04-13T23:37:40.841+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:37:40.841+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:37:40.841+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:37:32.434295+00:00
[2025-04-13T23:37:40.842+0000] {logging_mixin.py:190} INFO - Task hostname:84d443f8c8f3 operator:PythonOperator
[2025-04-13T23:37:40.862+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:37:40.873+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:37:40.874+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:40:38.488+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:40:38.504+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:40:38.512+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:40:38.512+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:40:38.518+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:40:38.522+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=90) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:40:38.523+0000] {standard_task_runner.py:72} INFO - Started process 92 to run task
[2025-04-13T23:40:38.524+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpyz1p0uy2']
[2025-04-13T23:40:38.525+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:40:38.550+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 68e962a0d2c5
[2025-04-13T23:40:38.594+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:40:38.595+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:40:38.595+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:40:38.595+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:40:38.504443+00:00
[2025-04-13T23:40:38.595+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:40:38.595+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:40:38.603+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-14 (offset=0)
[2025-04-13T23:40:39.510+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-15 (offset=0)
[2025-04-13T23:40:39.884+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-16 (offset=0)
[2025-04-13T23:40:40.218+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-17 (offset=0)
[2025-04-13T23:40:40.636+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-18 (offset=0)
[2025-04-13T23:40:40.950+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-19 (offset=0)
[2025-04-13T23:40:41.287+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-20 (offset=0)
[2025-04-13T23:40:41.685+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-21 (offset=0)
[2025-04-13T23:40:42.018+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-22 (offset=0)
[2025-04-13T23:40:42.350+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-23 (offset=0)
[2025-04-13T23:40:42.823+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:40:42.829+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:40:42.829+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T234038, end_date=20250413T234042
[2025-04-13T23:40:42.842+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:40:42.842+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:40:42.842+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:40:33.544092+00:00
[2025-04-13T23:40:42.843+0000] {logging_mixin.py:190} INFO - Task hostname:68e962a0d2c5 operator:PythonOperator
[2025-04-13T23:40:42.848+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:40:42.862+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:40:42.863+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:43:01.871+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:43:01.882+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:43:01.886+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:43:01.887+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:43:01.894+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:43:01.897+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=83) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:43:01.898+0000] {standard_task_runner.py:72} INFO - Started process 85 to run task
[2025-04-13T23:43:01.899+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphesblxtq']
[2025-04-13T23:43:01.899+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:43:01.927+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 0b262730a036
[2025-04-13T23:43:01.964+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:43:01.965+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:43:01.966+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:43:01.966+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:43:01.883030+00:00
[2025-04-13T23:43:01.966+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:43:01.966+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:43:01.972+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-14 (offset=0)
[2025-04-13T23:43:02.904+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-15 (offset=0)
[2025-04-13T23:43:03.344+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-16 (offset=0)
[2025-04-13T23:43:03.709+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-17 (offset=0)
[2025-04-13T23:43:04.071+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-18 (offset=0)
[2025-04-13T23:43:04.408+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-19 (offset=0)
[2025-04-13T23:43:04.793+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-20 (offset=0)
[2025-04-13T23:43:05.179+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-21 (offset=0)
[2025-04-13T23:43:05.559+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-22 (offset=0)
[2025-04-13T23:43:05.944+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-04-23 (offset=0)
[2025-04-13T23:43:06.344+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:43:06.352+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:43:06.352+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T234301, end_date=20250413T234306
[2025-04-13T23:43:06.364+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:43:06.364+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:43:06.364+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:42:56.845209+00:00
[2025-04-13T23:43:06.364+0000] {logging_mixin.py:190} INFO - Task hostname:0b262730a036 operator:PythonOperator
[2025-04-13T23:43:06.384+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:43:06.430+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:43:06.432+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:51:41.665+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:51:41.684+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:51:41.689+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:51:41.690+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:51:41.696+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): fetch_permits_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:51:41.700+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=104) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:51:41.701+0000] {standard_task_runner.py:72} INFO - Started process 106 to run task
[2025-04-13T23:51:41.703+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'fetch_permits_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpzvhbodw2']
[2025-04-13T23:51:41.704+0000] {standard_task_runner.py:105} INFO - Job 4: Subtask fetch_permits_task
[2025-04-13T23:51:41.733+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.fetch_permits_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 1544e177cd91
[2025-04-13T23:51:41.772+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='fetch_permits_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:51:41.774+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:51:41.774+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:51:41.775+0000] {logging_mixin.py:190} INFO - Current task name:fetch_permits_task state:running start_date:2025-04-13 23:51:41.684586+00:00
[2025-04-13T23:51:41.775+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:51:41.775+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:51:41.781+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-02 (offset=0)
[2025-04-13T23:51:42.486+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-03 (offset=0)
[2025-04-13T23:51:42.624+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-04 (offset=0)
[2025-04-13T23:51:42.774+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-05 (offset=0)
[2025-04-13T23:51:42.997+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-06 (offset=0)
[2025-04-13T23:51:43.159+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-07 (offset=0)
[2025-04-13T23:51:43.332+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-08 (offset=0)
[2025-04-13T23:51:43.479+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-09 (offset=0)
[2025-04-13T23:51:43.628+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-10 (offset=0)
[2025-04-13T23:51:43.810+0000] {logging_mixin.py:190} INFO - Fetching records for 2020-05-11 (offset=0)
[2025-04-13T23:51:43.953+0000] {python.py:240} INFO - Done. Returned value was: None
[2025-04-13T23:51:43.962+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:51:43.962+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=fetch_permits_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T235141, end_date=20250413T235143
[2025-04-13T23:51:43.977+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:51:43.977+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:51:43.978+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:51:35.678353+00:00
[2025-04-13T23:51:43.978+0000] {logging_mixin.py:190} INFO - Task hostname:1544e177cd91 operator:PythonOperator
[2025-04-13T23:51:44.013+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:51:44.028+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:51:44.029+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
