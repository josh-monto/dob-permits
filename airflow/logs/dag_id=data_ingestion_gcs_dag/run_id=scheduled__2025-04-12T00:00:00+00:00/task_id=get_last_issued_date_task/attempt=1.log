[2025-04-13T04:25:59.253+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:25:59.262+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:25:59.266+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:25:59.266+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:25:59.272+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:25:59.276+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:25:59.277+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T04:25:59.278+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppjgcqvcy']
[2025-04-13T04:25:59.279+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T04:25:59.305+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host e117c5077d30
[2025-04-13T04:25:59.348+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:25:59.349+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:25:59.349+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:25:59.349+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 04:25:59.262717+00:00
[2025-04-13T04:25:59.349+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:25:59.349+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:25:59.750+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T04:25:59.801+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:25:59.802+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T042559, end_date=20250413T042559
[2025-04-13T04:25:59.832+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T04:25:59.832+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T04:25:59.833+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 04:25:56.583174+00:00
[2025-04-13T04:25:59.833+0000] {logging_mixin.py:190} INFO - Task hostname:e117c5077d30 operator:PythonOperator
[2025-04-13T04:25:59.868+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T04:25:59.894+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:25:59.895+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:40:16.137+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:40:16.145+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:40:16.149+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:40:16.150+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:40:16.156+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:40:16.159+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=80) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:40:16.160+0000] {standard_task_runner.py:72} INFO - Started process 82 to run task
[2025-04-13T04:40:16.161+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp3jg24yax']
[2025-04-13T04:40:16.161+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T04:40:16.188+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 2cb45634cec3
[2025-04-13T04:40:16.228+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:40:16.229+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:40:16.229+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:40:16.229+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 04:40:16.146177+00:00
[2025-04-13T04:40:16.229+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:40:16.230+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:40:16.657+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T04:40:16.691+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:40:16.692+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T044016, end_date=20250413T044016
[2025-04-13T04:40:16.709+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T04:40:16.709+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T04:40:16.709+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 04:40:13.583186+00:00
[2025-04-13T04:40:16.710+0000] {logging_mixin.py:190} INFO - Task hostname:2cb45634cec3 operator:PythonOperator
[2025-04-13T04:40:16.752+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T04:40:16.792+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:40:16.793+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:51:42.388+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:51:42.395+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:51:42.399+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:51:42.399+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:51:42.405+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:51:42.409+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=86) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:51:42.410+0000] {standard_task_runner.py:72} INFO - Started process 88 to run task
[2025-04-13T04:51:42.412+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp59czprjg']
[2025-04-13T04:51:42.413+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T04:51:42.437+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host dbcd52eb1b2e
[2025-04-13T04:51:42.479+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:51:42.480+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:51:42.480+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:51:42.480+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 04:51:42.396098+00:00
[2025-04-13T04:51:42.480+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:51:42.480+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:51:42.868+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T04:51:42.903+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:51:42.903+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T045142, end_date=20250413T045142
[2025-04-13T04:51:42.918+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T04:51:42.919+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T04:51:42.919+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 04:51:39.748271+00:00
[2025-04-13T04:51:42.919+0000] {logging_mixin.py:190} INFO - Task hostname:dbcd52eb1b2e operator:PythonOperator
[2025-04-13T04:51:42.963+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T04:51:43.000+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:51:43.001+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T04:54:55.997+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T04:54:56.015+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:54:56.022+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T04:54:56.022+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T04:54:56.029+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T04:54:56.033+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T04:54:56.034+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T04:54:56.034+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpr640t6fj']
[2025-04-13T04:54:56.035+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T04:54:56.060+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 2bc808719a13
[2025-04-13T04:54:56.097+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T04:54:56.098+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T04:54:56.099+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T04:54:56.099+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 04:54:56.016421+00:00
[2025-04-13T04:54:56.099+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T04:54:56.099+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T04:54:56.507+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T04:54:56.548+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T04:54:56.548+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T045456, end_date=20250413T045456
[2025-04-13T04:54:56.567+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T04:54:56.567+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T04:54:56.567+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 04:54:53.369753+00:00
[2025-04-13T04:54:56.567+0000] {logging_mixin.py:190} INFO - Task hostname:2bc808719a13 operator:PythonOperator
[2025-04-13T04:54:56.589+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T04:54:56.605+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T04:54:56.606+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T05:00:22.817+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T05:00:22.826+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:00:22.829+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:00:22.830+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T05:00:22.835+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T05:00:22.839+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=80) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T05:00:22.840+0000] {standard_task_runner.py:72} INFO - Started process 82 to run task
[2025-04-13T05:00:22.841+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpnj8qrhko']
[2025-04-13T05:00:22.842+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T05:00:22.866+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 6cba399dd19a
[2025-04-13T05:00:22.904+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T05:00:22.905+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T05:00:22.906+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T05:00:22.906+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 05:00:22.826498+00:00
[2025-04-13T05:00:22.906+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T05:00:22.906+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T05:00:23.280+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T05:00:23.295+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T05:00:23.296+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T050022, end_date=20250413T050023
[2025-04-13T05:00:23.316+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T05:00:23.316+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T05:00:23.317+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 05:00:20.262467+00:00
[2025-04-13T05:00:23.317+0000] {logging_mixin.py:190} INFO - Task hostname:6cba399dd19a operator:PythonOperator
[2025-04-13T05:00:23.350+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T05:00:23.399+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T05:00:23.401+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T05:07:05.406+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T05:07:05.416+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:07:05.420+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T05:07:05.420+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T05:07:05.427+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T05:07:05.431+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T05:07:05.432+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T05:07:05.434+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmppvqrc97j']
[2025-04-13T05:07:05.435+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T05:07:05.466+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host d7194c8f2778
[2025-04-13T05:07:05.510+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T05:07:05.511+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T05:07:05.511+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T05:07:05.511+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 05:07:05.416571+00:00
[2025-04-13T05:07:05.511+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T05:07:05.511+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T05:07:05.909+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T05:07:05.958+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T05:07:05.959+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T050705, end_date=20250413T050705
[2025-04-13T05:07:06.009+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T05:07:06.010+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T05:07:06.011+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 05:07:02.854448+00:00
[2025-04-13T05:07:06.012+0000] {logging_mixin.py:190} INFO - Task hostname:d7194c8f2778 operator:PythonOperator
[2025-04-13T05:07:06.065+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T05:07:06.100+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T05:07:06.101+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:34:55.012+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:34:55.024+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:34:55.028+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:34:55.028+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:34:55.035+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:34:55.040+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:34:55.041+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T16:34:55.042+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm9xm6anh']
[2025-04-13T16:34:55.042+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T16:34:55.076+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host c8daa6a1af90
[2025-04-13T16:34:55.122+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:34:55.123+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:34:55.123+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:34:55.124+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 16:34:55.024313+00:00
[2025-04-13T16:34:55.124+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:34:55.125+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:34:56.656+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T16:34:56.672+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:34:56.673+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T163455, end_date=20250413T163456
[2025-04-13T16:34:56.688+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:34:56.688+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:34:56.688+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:34:52.260133+00:00
[2025-04-13T16:34:56.689+0000] {logging_mixin.py:190} INFO - Task hostname:c8daa6a1af90 operator:PythonOperator
[2025-04-13T16:34:56.697+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:34:56.715+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:34:56.717+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:45:32.521+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:45:32.531+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:45:32.535+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:45:32.535+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:45:32.541+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:45:32.545+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=142) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:45:32.546+0000] {standard_task_runner.py:72} INFO - Started process 144 to run task
[2025-04-13T16:45:32.546+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp1d4zw788']
[2025-04-13T16:45:32.547+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T16:45:32.573+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host c4adc78e7cfa
[2025-04-13T16:45:32.615+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:45:32.616+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:45:32.617+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:45:32.617+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 16:45:32.531651+00:00
[2025-04-13T16:45:32.617+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:45:32.617+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:45:33.815+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T16:45:33.863+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:45:33.864+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T164532, end_date=20250413T164533
[2025-04-13T16:45:33.898+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:45:33.899+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:45:33.899+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:45:29.898336+00:00
[2025-04-13T16:45:33.900+0000] {logging_mixin.py:190} INFO - Task hostname:c4adc78e7cfa operator:PythonOperator
[2025-04-13T16:45:33.915+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:45:33.933+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:45:33.935+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T16:49:48.714+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T16:49:48.722+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:49:48.726+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T16:49:48.726+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T16:49:48.732+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T16:49:48.736+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T16:49:48.737+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T16:49:48.737+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp5s7xne9z']
[2025-04-13T16:49:48.738+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T16:49:48.763+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host f05686b2dc59
[2025-04-13T16:49:48.804+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T16:49:48.805+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T16:49:48.805+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T16:49:48.805+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 16:49:48.723154+00:00
[2025-04-13T16:49:48.805+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T16:49:48.806+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T16:49:49.940+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T16:49:49.957+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T16:49:49.958+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T164948, end_date=20250413T164949
[2025-04-13T16:49:49.976+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T16:49:49.977+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T16:49:49.977+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 16:49:46.134601+00:00
[2025-04-13T16:49:49.977+0000] {logging_mixin.py:190} INFO - Task hostname:f05686b2dc59 operator:PythonOperator
[2025-04-13T16:49:50.027+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T16:49:50.050+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T16:49:50.051+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T17:06:44.197+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T17:06:44.205+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T17:06:44.209+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T17:06:44.209+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T17:06:44.215+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T17:06:44.219+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=93) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T17:06:44.220+0000] {standard_task_runner.py:72} INFO - Started process 95 to run task
[2025-04-13T17:06:44.221+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmphlskzi4b']
[2025-04-13T17:06:44.222+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T17:06:44.255+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 1cc4ef4172c3
[2025-04-13T17:06:44.298+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T17:06:44.299+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T17:06:44.299+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T17:06:44.299+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 17:06:44.205913+00:00
[2025-04-13T17:06:44.300+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T17:06:44.300+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T17:06:45.470+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T17:06:45.498+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T17:06:45.498+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T170644, end_date=20250413T170645
[2025-04-13T17:06:45.512+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T17:06:45.513+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T17:06:45.513+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 17:06:41.545310+00:00
[2025-04-13T17:06:45.513+0000] {logging_mixin.py:190} INFO - Task hostname:1cc4ef4172c3 operator:PythonOperator
[2025-04-13T17:06:45.549+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T17:06:45.569+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T17:06:45.570+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T22:49:58.907+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T22:49:58.915+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:49:58.919+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:49:58.919+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T22:49:58.925+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T22:49:58.928+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=218) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T22:49:58.929+0000] {standard_task_runner.py:72} INFO - Started process 220 to run task
[2025-04-13T22:49:58.930+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp28698upg']
[2025-04-13T22:49:58.931+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T22:49:58.957+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host e66f5071272b
[2025-04-13T22:49:58.999+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T22:49:59.000+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T22:49:59.001+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T22:49:59.001+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 22:49:58.915816+00:00
[2025-04-13T22:49:59.001+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T22:49:59.001+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T22:50:00.551+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T22:50:00.586+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T22:50:00.587+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T224958, end_date=20250413T225000
[2025-04-13T22:50:00.634+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T22:50:00.634+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T22:50:00.635+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 22:49:56.330855+00:00
[2025-04-13T22:50:00.636+0000] {logging_mixin.py:190} INFO - Task hostname:e66f5071272b operator:PythonOperator
[2025-04-13T22:50:00.670+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T22:50:00.711+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T22:50:00.713+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T22:51:59.040+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T22:51:59.048+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:51:59.052+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T22:51:59.052+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T22:51:59.058+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T22:51:59.062+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=86) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T22:51:59.063+0000] {standard_task_runner.py:72} INFO - Started process 88 to run task
[2025-04-13T22:51:59.064+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpn5o6jqm1']
[2025-04-13T22:51:59.064+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T22:51:59.090+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host f545404fc07f
[2025-04-13T22:51:59.129+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T22:51:59.130+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T22:51:59.131+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T22:51:59.131+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 22:51:59.048679+00:00
[2025-04-13T22:51:59.131+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T22:51:59.131+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T22:52:00.272+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T22:52:00.305+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T22:52:00.305+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T225159, end_date=20250413T225200
[2025-04-13T22:52:00.324+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T22:52:00.324+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T22:52:00.324+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 22:51:56.480715+00:00
[2025-04-13T22:52:00.325+0000] {logging_mixin.py:190} INFO - Task hostname:f545404fc07f operator:PythonOperator
[2025-04-13T22:52:00.352+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T22:52:00.398+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T22:52:00.400+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:07:39.250+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:07:39.258+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:07:39.263+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:07:39.263+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:07:39.272+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:07:39.276+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:07:39.277+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T23:07:39.278+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpgojzz1_n']
[2025-04-13T23:07:39.278+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:07:39.303+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 3aaac60a2eb2
[2025-04-13T23:07:39.343+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:07:39.345+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:07:39.345+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:07:39.345+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:07:39.259092+00:00
[2025-04-13T23:07:39.345+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:07:39.345+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:07:40.715+0000] {python.py:240} INFO - Done. Returned value was: 2025-04-10T00:00:00.000
[2025-04-13T23:07:40.728+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:07:40.729+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T230739, end_date=20250413T230740
[2025-04-13T23:07:40.742+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:07:40.742+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:07:40.742+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:07:36.629415+00:00
[2025-04-13T23:07:40.742+0000] {logging_mixin.py:190} INFO - Task hostname:3aaac60a2eb2 operator:PythonOperator
[2025-04-13T23:07:40.769+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:07:40.783+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:07:40.784+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:26:13.271+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:26:13.282+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:26:13.286+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:26:13.286+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:26:13.292+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:26:13.296+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=121) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:26:13.297+0000] {standard_task_runner.py:72} INFO - Started process 123 to run task
[2025-04-13T23:26:13.298+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp_27hnrs2']
[2025-04-13T23:26:13.299+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:26:13.332+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 9e340cbd440e
[2025-04-13T23:26:13.375+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:26:13.377+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:26:13.377+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:26:13.377+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:26:13.282561+00:00
[2025-04-13T23:26:13.377+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:26:13.378+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:26:14.285+0000] {taskinstance.py:3313} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 53, in get_last_issued_date
    rows = query_job.result()  # Waits for query to finish
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/query.py", line 1590, in result
    do_get_result()
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 153, in retry_target
    _retry_error_helper(
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 144, in retry_target
    result = target()
             ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/query.py", line 1579, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/base.py", line 971, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/future/polling.py", line 261, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet; reason: invalid, location: gs://nyc-projects-455321-bucket/raw/building_permits.parquet, message: Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet

Location: US
Job ID: b56b23a3-7f4a-4ec0-a793-2c1b6a5da119

[2025-04-13T23:26:14.305+0000] {logging_mixin.py:190} INFO - Task instance in failure state
[2025-04-13T23:26:14.306+0000] {logging_mixin.py:190} INFO - Task start:2025-04-13 23:26:13.282561+00:00 end:2025-04-13 23:26:14.305341+00:00 duration:1.02278
[2025-04-13T23:26:14.306+0000] {logging_mixin.py:190} INFO - Task:<Task(PythonOperator): get_last_issued_date_task> dag:<DAG: data_ingestion_gcs_dag> dagrun:<DagRun data_ingestion_gcs_dag @ 2025-04-12 00:00:00+00:00: scheduled__2025-04-12T00:00:00+00:00, state:running, queued_at: 2025-04-13 23:26:10.686289+00:00. externally triggered: False>
[2025-04-13T23:26:14.307+0000] {logging_mixin.py:190} INFO - Failure caused by 400 Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet; reason: invalid, location: gs://nyc-projects-455321-bucket/raw/building_permits.parquet, message: Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet

Location: US
Job ID: b56b23a3-7f4a-4ec0-a793-2c1b6a5da119
[2025-04-13T23:26:14.307+0000] {taskinstance.py:1226} INFO - Marking task as UP_FOR_RETRY. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T232613, end_date=20250413T232614
[2025-04-13T23:26:14.332+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:26:14.333+0000] {standard_task_runner.py:124} ERROR - Failed to execute job 3 for task get_last_issued_date_task (400 Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet; reason: invalid, location: gs://nyc-projects-455321-bucket/raw/building_permits.parquet, message: Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet

Location: US
Job ID: b56b23a3-7f4a-4ec0-a793-2c1b6a5da119
; 123)
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/task/task_runner/standard_task_runner.py", line 117, in _start_by_fork
    ret = args.func(args, dag=self.dag)
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/cli_config.py", line 49, in command
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/cli.py", line 116, in wrapper
    return f(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 483, in task_run
    task_return_code = _run_task_by_selected_method(args, _dag, ti)
                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 256, in _run_task_by_selected_method
    return _run_raw_task(args, ti)
           ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/cli/commands/task_command.py", line 341, in _run_raw_task
    return ti._run_raw_task(
           ^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/session.py", line 97, in wrapper
    return func(*args, session=session, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3006, in _run_raw_task
    return _run_raw_task(
           ^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 274, in _run_raw_task
    TaskInstance._execute_task_with_callbacks(
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3161, in _execute_task_with_callbacks
    result = self._execute_task(context, task_orig)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 3185, in _execute_task
    return _execute_task(self, context, task_orig)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 768, in _execute_task
    result = _execute_callable(context=context, **execute_callable_kwargs)
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/taskinstance.py", line 734, in _execute_callable
    return ExecutionCallableRunner(
           ^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/models/baseoperator.py", line 424, in wrapper
    return func(self, *args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 238, in execute
    return_value = self.execute_callable()
                   ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/operators/python.py", line 256, in execute_callable
    return runner.run(*self.op_args, **self.op_kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/airflow/utils/operator_helpers.py", line 252, in run
    return self.func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/opt/airflow/dags/data_ingestion_gcs_dag.py", line 53, in get_last_issued_date
    rows = query_job.result()  # Waits for query to finish
           ^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/query.py", line 1590, in result
    do_get_result()
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 293, in retry_wrapped_func
    return retry_target(
           ^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 153, in retry_target
    _retry_error_helper(
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_base.py", line 212, in _retry_error_helper
    raise final_exc from source_exc
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/retry/retry_unary.py", line 144, in retry_target
    result = target()
             ^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/query.py", line 1579, in do_get_result
    super(QueryJob, self).result(retry=retry, timeout=timeout)
  File "/home/airflow/.local/lib/python3.12/site-packages/google/cloud/bigquery/job/base.py", line 971, in result
    return super(_AsyncJob, self).result(timeout=timeout, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/airflow/.local/lib/python3.12/site-packages/google/api_core/future/polling.py", line 261, in result
    raise self._exception
google.api_core.exceptions.BadRequest: 400 Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet; reason: invalid, location: gs://nyc-projects-455321-bucket/raw/building_permits.parquet, message: Error while reading table: nyc-projects-455321.building_permits.external_table, error message: Failed to expand table nyc-projects-455321.building_permits.external_table with file pattern gs://nyc-projects-455321-bucket/raw/building_permits.parquet: matched no files. File: gs://nyc-projects-455321-bucket/raw/building_permits.parquet

Location: US
Job ID: b56b23a3-7f4a-4ec0-a793-2c1b6a5da119

[2025-04-13T23:26:14.340+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 1
[2025-04-13T23:26:14.351+0000] {taskinstance.py:3901} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:26:14.352+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:30:45.745+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:30:45.753+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:30:45.757+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:30:45.757+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:30:45.763+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:30:45.767+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=101) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:30:45.768+0000] {standard_task_runner.py:72} INFO - Started process 103 to run task
[2025-04-13T23:30:45.768+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpm8zwcl3k']
[2025-04-13T23:30:45.769+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:30:45.793+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 15a7108b06f8
[2025-04-13T23:30:45.833+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:30:45.834+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:30:45.834+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:30:45.834+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:30:45.754171+00:00
[2025-04-13T23:30:45.834+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:30:45.834+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:30:46.228+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T23:30:46.264+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:30:46.265+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T233045, end_date=20250413T233046
[2025-04-13T23:30:46.278+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:30:46.278+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:30:46.278+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:30:43.197349+00:00
[2025-04-13T23:30:46.279+0000] {logging_mixin.py:190} INFO - Task hostname:15a7108b06f8 operator:PythonOperator
[2025-04-13T23:30:46.317+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:30:46.334+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:30:46.335+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:37:35.016+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:37:35.027+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:37:35.031+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:37:35.031+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:37:35.040+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:37:35.044+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:37:35.046+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T23:37:35.046+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpjah608pq']
[2025-04-13T23:37:35.047+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:37:35.074+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 84d443f8c8f3
[2025-04-13T23:37:35.138+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:37:35.139+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:37:35.139+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:37:35.139+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:37:35.027645+00:00
[2025-04-13T23:37:35.139+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:37:35.140+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:37:35.467+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T23:37:35.480+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:37:35.480+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T233735, end_date=20250413T233735
[2025-04-13T23:37:35.491+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:37:35.491+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:37:35.491+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:37:32.434295+00:00
[2025-04-13T23:37:35.492+0000] {logging_mixin.py:190} INFO - Task hostname:84d443f8c8f3 operator:PythonOperator
[2025-04-13T23:37:35.516+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:37:35.531+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:37:35.532+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:40:36.240+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:40:36.249+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:40:36.255+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:40:36.255+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:40:36.262+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:40:36.267+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:40:36.268+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T23:40:36.268+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpsmw4_un7']
[2025-04-13T23:40:36.269+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:40:36.296+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 68e962a0d2c5
[2025-04-13T23:40:36.337+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:40:36.338+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:40:36.338+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:40:36.338+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:40:36.249902+00:00
[2025-04-13T23:40:36.338+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:40:36.338+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:40:36.713+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T23:40:36.772+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:40:36.773+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T234036, end_date=20250413T234036
[2025-04-13T23:40:36.804+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:40:36.805+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:40:36.805+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:40:33.544092+00:00
[2025-04-13T23:40:36.805+0000] {logging_mixin.py:190} INFO - Task hostname:68e962a0d2c5 operator:PythonOperator
[2025-04-13T23:40:36.821+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:40:36.848+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:40:36.849+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:42:59.488+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:42:59.503+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:42:59.509+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:42:59.509+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:42:59.515+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:42:59.520+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=79) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:42:59.520+0000] {standard_task_runner.py:72} INFO - Started process 81 to run task
[2025-04-13T23:42:59.522+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmpc64tb107']
[2025-04-13T23:42:59.523+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:42:59.552+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 0b262730a036
[2025-04-13T23:42:59.591+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:42:59.592+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:42:59.592+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:42:59.592+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:42:59.503878+00:00
[2025-04-13T23:42:59.592+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:42:59.592+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:42:59.966+0000] {python.py:240} INFO - Done. Returned value was: 2020-04-14T00:00:00.000
[2025-04-13T23:42:59.997+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:42:59.998+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T234259, end_date=20250413T234259
[2025-04-13T23:43:00.010+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:43:00.011+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:43:00.011+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:42:56.845209+00:00
[2025-04-13T23:43:00.011+0000] {logging_mixin.py:190} INFO - Task hostname:0b262730a036 operator:PythonOperator
[2025-04-13T23:43:00.029+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:43:00.046+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:43:00.047+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
[2025-04-13T23:51:38.226+0000] {local_task_job_runner.py:123} INFO - ::group::Pre task execution logs
[2025-04-13T23:51:38.235+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:51:38.238+0000] {taskinstance.py:2614} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [queued]>
[2025-04-13T23:51:38.239+0000] {taskinstance.py:2867} INFO - Starting attempt 1 of 2
[2025-04-13T23:51:38.245+0000] {taskinstance.py:2890} INFO - Executing <Task(PythonOperator): get_last_issued_date_task> on 2025-04-12 00:00:00+00:00
[2025-04-13T23:51:38.248+0000] {warnings.py:112} WARNING - /home/***/.local/lib/python3.12/site-packages/***/task/task_runner/standard_task_runner.py:70: DeprecationWarning: This process (pid=100) is multi-threaded, use of fork() may lead to deadlocks in the child.
  pid = os.fork()

[2025-04-13T23:51:38.249+0000] {standard_task_runner.py:72} INFO - Started process 102 to run task
[2025-04-13T23:51:38.250+0000] {standard_task_runner.py:104} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcs_dag', 'get_last_issued_date_task', 'scheduled__2025-04-12T00:00:00+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/data_ingestion_gcs_dag.py', '--cfg-path', '/tmp/tmp0ck5dtaf']
[2025-04-13T23:51:38.250+0000] {standard_task_runner.py:105} INFO - Job 3: Subtask get_last_issued_date_task
[2025-04-13T23:51:38.277+0000] {task_command.py:467} INFO - Running <TaskInstance: data_ingestion_gcs_dag.get_last_issued_date_task scheduled__2025-04-12T00:00:00+00:00 [running]> on host 1544e177cd91
[2025-04-13T23:51:38.318+0000] {taskinstance.py:3134} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='data_ingestion_gcs_dag' AIRFLOW_CTX_TASK_ID='get_last_issued_date_task' AIRFLOW_CTX_EXECUTION_DATE='2025-04-12T00:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2025-04-12T00:00:00+00:00'
[2025-04-13T23:51:38.319+0000] {logging_mixin.py:190} INFO - Task instance is in running state
[2025-04-13T23:51:38.319+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: queued
[2025-04-13T23:51:38.319+0000] {logging_mixin.py:190} INFO - Current task name:get_last_issued_date_task state:running start_date:2025-04-13 23:51:38.235414+00:00
[2025-04-13T23:51:38.319+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag and current dag run status:running
[2025-04-13T23:51:38.320+0000] {taskinstance.py:732} INFO - ::endgroup::
[2025-04-13T23:51:39.720+0000] {python.py:240} INFO - Done. Returned value was: 2020-05-02T00:00:00.000
[2025-04-13T23:51:39.745+0000] {taskinstance.py:341} INFO - ::group::Post task execution logs
[2025-04-13T23:51:39.745+0000] {taskinstance.py:353} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcs_dag, task_id=get_last_issued_date_task, run_id=scheduled__2025-04-12T00:00:00+00:00, execution_date=20250412T000000, start_date=20250413T235138, end_date=20250413T235139
[2025-04-13T23:51:39.757+0000] {logging_mixin.py:190} INFO - Task instance in success state
[2025-04-13T23:51:39.757+0000] {logging_mixin.py:190} INFO -  Previous state of the Task instance: running
[2025-04-13T23:51:39.758+0000] {logging_mixin.py:190} INFO - Dag name:data_ingestion_gcs_dag queued_at:2025-04-13 23:51:35.678353+00:00
[2025-04-13T23:51:39.758+0000] {logging_mixin.py:190} INFO - Task hostname:1544e177cd91 operator:PythonOperator
[2025-04-13T23:51:39.783+0000] {local_task_job_runner.py:266} INFO - Task exited with return code 0
[2025-04-13T23:51:39.804+0000] {taskinstance.py:3901} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2025-04-13T23:51:39.805+0000] {local_task_job_runner.py:245} INFO - ::endgroup::
